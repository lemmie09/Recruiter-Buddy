{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3657cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import requests \n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636ce11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-medium\"\n",
    "API_TOKEN = \"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\"  # Replace with your actual Hugging Face API token\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3976a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_and_save_audio(output_file=\"output1.mp3\", duration=5, sample_rate=44100):\n",
    "    print(\"Recording... Press Ctrl+C to stop.\")\n",
    "\n",
    "    # Record audio\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=2, dtype=np.int16)\n",
    "    sd.wait()\n",
    "\n",
    "    # Convert audio data to AudioSegment\n",
    "    audio_segment = AudioSegment(\n",
    "        audio_data.tobytes(),\n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=audio_data.dtype.itemsize,\n",
    "        channels=2\n",
    "    )\n",
    "\n",
    "    # Save as MP3\n",
    "    audio_segment.export(output_file, format=\"mp3\")\n",
    "\n",
    "    print(f\"Recording saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d55572d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Ctrl+C to stop.\n",
      "Recording saved as output1.mp3\n"
     ]
    }
   ],
   "source": [
    "audio_input = record_and_save_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ca39cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_hindi_speech_recognition(mp3_filename):\n",
    "    with open(mp3_filename, \"rb\") as f:\n",
    "        mp3_data = f.read()\n",
    "\n",
    "    flac_data = convert_mp3_to_flac(mp3_data)\n",
    "\n",
    "    response = requests.post(API_URL, data=flac_data, headers={'Content-Type': 'audio/flac'})\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5daabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_flac(mp3_data):\n",
    "    audio = AudioSegment.from_mp3(io.BytesIO(mp3_data))\n",
    "    flac_data = audio.export(format=\"flac\").read()\n",
    "    return flac_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a7acfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Python is a high level general purpose program.'}\n"
     ]
    }
   ],
   "source": [
    "mp3_file_path = \"C:/Users/HP/Downloads/recruiter buddy/output1.mp3\"\n",
    "output1 = query_hindi_speech_recognition(mp3_file_path)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f748acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = output1[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4af2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5d3b5b",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87a577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL1 = \"https://api-inference.huggingface.co/models/Falconsai/text_summarization\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL1, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": temp,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c24a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Hello, my name is Kinjal . Hello, My name is Kenjal. I am a member of a group of friends .'}]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d562a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Preprocess the answers\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(answer):\n",
    "    answer = answer.lower()\n",
    "    tokens = word_tokenize(answer)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def give_similarity(correct_answer,student_answer):\n",
    "    # Identify important keywords\n",
    "    #correct_answer = \"Python is a computer programming language often used to build websites and software, automate tasks, and analyze data. Python is a general-purpose language, not specialized for any specific problems, and used to create various programmes..\"\n",
    "    correct_tokens = preprocess(correct_answer)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([correct_answer])\n",
    "    important_keywords = [vectorizer.get_feature_names_out()[i] for i in tfidf_matrix.nonzero()[1]]\n",
    "\n",
    "    # Check for keyword presence\n",
    "    #student_answer = \"Python is a computer programming language often used to build websites and software, automate tasks, and analyze data. \"\n",
    "    student_tokens = preprocess(student_answer)\n",
    "    present_keywords = set(important_keywords) & set(student_tokens)\n",
    "    print(\"Present keywords:\", present_keywords)\n",
    "\n",
    "    # Calculate answer similarity\n",
    "    student_tfidf = vectorizer.transform([student_answer])\n",
    "    similarity = cosine_similarity(tfidf_matrix, student_tfidf)[0][0]\n",
    "    return similarity * 100\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a071e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present keywords: {'language', 'data', 'software', 'automate', 'used', 'websites', 'programming', 'often', 'computer', 'python', 'analyze', 'build', 'tasks'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.35513898799657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_answer = \"Python is a computer programming language often used to build websites and software, automate tasks, and analyze data. Python is a general-purpose language, not specialized for any specific problems, and used to create various programmes..\"\n",
    "student_answer = \"Python is a computer programming language often used to build websites and software, automate tasks, and analyze data. \"\n",
    "score = give_similarity(correct_answer,student_answer)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1954b7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.35513898799657"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf83035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Introduction of Data Science\n",
      "What is data science?\n",
      "Topic: Components of Data Science\n",
      "What are the key components of data science?\n",
      "Topic: Data Science vs Traditional Statistic\n",
      "How does data science differ from traditional statistics?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('data/DataScience.csv')\n",
    "\n",
    "# User provided list of topics\n",
    "user_topics = ['Introduction of Data Science', 'Components of Data Science', 'Data Science vs Traditional Statistic']\n",
    "\n",
    "# Extract unique questions for the user-provided topics\n",
    "selected_questions = {}\n",
    "for topic in user_topics:\n",
    "    topic_questions = df[df['Topic'] == topic]['Question'].unique().tolist()\n",
    "    selected_questions[topic] = random.sample(topic_questions, len(topic_questions))\n",
    "\n",
    "# Calculate the total number of questions required\n",
    "total_questions = 2  # Total number of questions needed\n",
    "\n",
    "# Check if total number of questions are met\n",
    "total_selected_questions = sum(len(questions) for questions in selected_questions.values())\n",
    "if total_selected_questions < total_questions:\n",
    "    # If total_questions is less than the number of topics provided, select a random subset of topics\n",
    "    if total_questions < len(user_topics):\n",
    "        user_topics = random.sample(user_topics, total_questions)\n",
    "    for topic in user_topics:\n",
    "        topic_questions = selected_questions[topic]\n",
    "        remaining_questions = df[df['Topic'] == topic]['Question'].unique().tolist()\n",
    "        remaining_questions = [question for question in remaining_questions if question not in topic_questions]\n",
    "        selected_questions[topic] += random.sample(remaining_questions, min(len(remaining_questions), total_questions // len(user_topics)))\n",
    "\n",
    "# Print selected questions\n",
    "for topic, topic_questions in selected_questions.items():\n",
    "    print(f'Topic: {topic}')\n",
    "    for question in topic_questions:\n",
    "        print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "654fd5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Introduction of Data Science\n",
      "Question: What is data science?\n",
      "----------------------\n",
      "Topic: Data Science vs Traditional Statistic\n",
      "Question: How does data science differ from traditional statistics?\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('data/DataScience.csv')\n",
    "\n",
    "# User provided list of topics\n",
    "user_topics = ['Introduction of Data Science', 'Components of Data Science', 'Data Science vs Traditional Statistic']\n",
    "\n",
    "# Extract unique questions for the user-provided topics\n",
    "selected_questions = {}\n",
    "for topic in user_topics:\n",
    "    topic_questions = df[df['Topic'] == topic]['Question'].unique().tolist()\n",
    "    selected_questions[topic] = random.sample(topic_questions, len(topic_questions))\n",
    "\n",
    "# Calculate the total number of questions required\n",
    "total_questions = 2  # Total number of questions needed\n",
    "\n",
    "# Randomly select questions until total number of questions equals specified total\n",
    "remaining_questions = []\n",
    "selected_topics = set()\n",
    "for topic, topic_questions in selected_questions.items():\n",
    "    selected_topics.add(topic)\n",
    "    remaining_questions.extend([(topic, question) for question in topic_questions])\n",
    "\n",
    "if len(remaining_questions) > total_questions:\n",
    "    remaining_questions = random.sample(remaining_questions, total_questions)\n",
    "\n",
    "# Print selected questions with topics\n",
    "for topic, question in remaining_questions:\n",
    "    print(f'Topic: {topic}')\n",
    "    print(f'Question: {question}')\n",
    "    print('----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e69033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Introduction of Data Science', 'In Which Year Data Science is Introduce?'), ('Introduction of Data Science', 'What is data science?'), ('Components of Data Science', 'What are the key components of data science?'), ('Data Science vs Traditional Statistic', 'How does data science differ from traditional statistics?')]\n",
      "Topic: Introduction of Data Science\n",
      "Question: In Which Year Data Science is Introduce?\n",
      "----------------------\n",
      "Topic: Introduction of Data Science\n",
      "Question: What is data science?\n",
      "----------------------\n",
      "Topic: Components of Data Science\n",
      "Question: What are the key components of data science?\n",
      "----------------------\n",
      "Topic: Data Science vs Traditional Statistic\n",
      "Question: How does data science differ from traditional statistics?\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('data/DataScience.csv')\n",
    "\n",
    "# User provided list of topics\n",
    "user_topics = ['Introduction of Data Science', 'Components of Data Science', 'Data Science vs Traditional Statistic']\n",
    "\n",
    "# Extract unique questions for the user-provided topics\n",
    "selected_questions = {}\n",
    "for topic in user_topics:\n",
    "    topic_questions = df[df['Topic'] == topic]['Question'].unique().tolist()\n",
    "    random.shuffle(topic_questions)  # Shuffle the questions for each topic\n",
    "    selected_questions[topic] = topic_questions\n",
    "\n",
    "# Calculate the total number of questions required\n",
    "total_questions = 4  # Total number of questions needed\n",
    "\n",
    "# Randomly select questions until total number of questions equals specified total\n",
    "remaining_questions = []\n",
    "selected_topics = set()\n",
    "for topic, topic_questions in selected_questions.items():\n",
    "    selected_topics.add(topic)\n",
    "    remaining_questions.extend([(topic, question) for question in topic_questions])\n",
    "\n",
    "if len(remaining_questions) > total_questions:\n",
    "    remaining_questions = random.sample(remaining_questions, total_questions)\n",
    "\n",
    "\n",
    "print(remaining_questions)\n",
    "# Print selected questions with topics\n",
    "for topic, question in remaining_questions:\n",
    "    print(f'Topic: {topic}')\n",
    "    print(f'Question: {question}')\n",
    "    print('----------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
